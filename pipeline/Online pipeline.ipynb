{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this code\n",
    "\n",
    "This script apply entire pipeline to new batch of tweets:<br>\n",
    "1. Pre-process\n",
    "2. Feature engineering step-1 (low computation)\n",
    "3. Relevance classification (0/1-irrelevant)\n",
    "4. Filter non relevant tweets\n",
    "5. Feature engineering step-2 (high computation)\n",
    "6. Support classification (-1/0/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "'min_couple_appearances': 0<br>\n",
    "'feature_selection': 'False', # When predicting new data - no auto features selection is applied.<br> \n",
    "                              #Specific features are selected by model needs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "            # Mode\n",
    "            'learning': False,           # True at the train phase, False when operational - predict new data using existing model\n",
    "            'distributed_pipeline': False,\n",
    "        \n",
    "            # Data\n",
    "            'filter_taggers': False,    # If to filter labeled data by the tagger - Yogev, Ofir and Itay\n",
    "            'target': 'relevance',        # The target of the algorithm\n",
    "            'load_df_from_pickle': False,# If to load a complete data-frame or to execute the entire pipeline from the beginning \n",
    "            \n",
    "            # Pre-process\n",
    "            'slang': True,              # If to handle slang words, also for Feature engineering\n",
    "            'spell_correction': False,  # If to use spell correction in the pre-proccess phase \n",
    "            'col': 'text',              # Column to apply pre-proccess on - used by the proccess_tweet function in tweet_pre_proccess.py\n",
    "            \n",
    "            # Feature engineering\n",
    "            'nlp_features': True,\n",
    "            'word_type': False,\n",
    "            'dominant_keywords': True,\n",
    "            'dominant_keywords_metric': 'smart_error', # entropy, purity, smart_error\n",
    "            'user_features': False,\n",
    "            'user_bio': False,\n",
    "            'time_and_event': False,    # Time and event features\n",
    "            'twitter_foundation_date': '2006-03-21 12:00:00',\n",
    "            'network_features': False,\n",
    "            'load_network_data': False,\n",
    "            'nlp_raw': True,\n",
    "            'emotion': False,\n",
    "            'hashtags_and_mentions': True,\n",
    "            'num_dominant_words': 100,  # Number of dominant words to use in the NLP features (dominant_keywords function - parameter k)\n",
    "            'min_word_appearances': 4,# Min number of appearnces (#tweets) for dominant word to be considered dominant\n",
    "            'min_couple_appearances': 4,# For couple of dominant words -\n",
    "                                        # how many time the combination need to appear in the data in order to become a feature        \n",
    "            'url_features': False,\n",
    "            'Tweets_media_and_content': True,\n",
    "            'country_support': False,\n",
    "            'entities_features': True,\n",
    "            'sentiment': False,          # NLTK sentiment feature\n",
    "    \n",
    "            # Feature selection\n",
    "            'feature_selection': False,\n",
    "            'remove_features_zero_variance': False,        \n",
    "            'remove_correlated_features': False,\n",
    "            'remove_low_correlated_features': False,\n",
    "            'feature_importance': False,\n",
    "            'corr_per_thresh': 0.0,    # Percentile threshold of Min correlation between a feature and the target variable (abs) \n",
    "            'importance_per_thresh': 33,# Percentile threshold of Min importance of a feature\n",
    "            'PCA': False,               # If the use PCA to reduce dimensiality\n",
    "            'PCA_var': 0.995,           # % of commulative explained variance required from PCA (affect #of PC)\n",
    "\n",
    "            # Model\n",
    "            'model': 'Random Forest',\n",
    "            'load_model_pickle': False, # If to import existing models from pickle\n",
    "            'regression': False,        # If to run regression model also\n",
    "            'validation': False,        # If to use train split to train and validation\n",
    "            'class_threshold': 0.43,     # Probability threshold in order to classify a tweet as negative/neurtal/positive\n",
    "            'bench_from_pickle': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import time\n",
    "import matplotlib\n",
    "import pickle\n",
    "from tqdm import tqdm, trange, tqdm_notebook, tqdm_pandas\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid trimming text in jupyter preview\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 1234\n",
    "tqdm.pandas(tqdm_notebook())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import thesis modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import domain_entities\n",
    "import nlp_url_features\n",
    "import tweet_pre_proccess\n",
    "import nlp_features\n",
    "import eda\n",
    "import ml_model\n",
    "import slang\n",
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../relevance algo')\n",
    "import relevance_prediction\n",
    "#import political_prediction\n",
    "os.chdir('../support algo')\n",
    "import support_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../relevance algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../../data/quoted_source_emotion.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Relevance Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "df object explanation:<br>\n",
    "    - df_relevance_no_filter_no_prediction = no filtered features, no prediction<br>\n",
    "    - df_relevance_no_filter_w_prediction.tsv = all features + relevance prediction<br>\n",
    "    - data_w_relevance = selected features for relevance algo + no prediction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, full_df = relevance_prediction.predict(data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summarize results\n",
    "plt.figure(num=None, figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "h = sns.countplot(x=config['target'], data=df, order = df[config['target']].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding relevance feature to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relevance'] = df['relevance'].values\n",
    "# data.to_csv('data_w_relevance.tsv', header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove irrelevants tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter irrelevant tweets using the relevance label/prediction\n",
    "full_df = relevance_prediction.remove_irrelevants(df, full_df)\n",
    "data = data[data.relevance!=2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change configuretion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change configuraion input\n",
    "config['target'] = 'support'\n",
    "config['sentiment'] = True\n",
    "config['emotion'] = True\n",
    "config['country_support'] = True\n",
    "config['word_type'] = True\n",
    "config['importance_per_thresh'] = 60\n",
    "config['num_dominant_words'] = 250\n",
    "config['user_features'] = True\n",
    "config['user_bio'] = True\n",
    "config['time_and_event'] = True    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding support features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_df = support_prediction.adding_features(full_df, config)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to 'support_df' - the data frame for the support algorithm (filtered features + support prediction)\n",
    "df, full_df = support_prediction.predict(full_df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize results\n",
    "plt.figure(num=None, figsize=(10, 6), facecolor='w', edgecolor='k')\n",
    "h = sns.countplot(x=config['target'], data=df, order = df[config['target']].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding support feature to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['support'] = df['support'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../pipeline/predictions/data_w_predictions_{}.tsv'.format(str(datetime.today()).split(' ')[0]), header=True, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
